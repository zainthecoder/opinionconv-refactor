{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT PACKAGES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import glob\n",
    "import string\n",
    "from joblib import load\n",
    "import pickle\n",
    "import logging\n",
    "import copy\n",
    "import textstat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "nlp_spacy = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD AMAZON DATASETS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the data\n",
    "import gzip  # Import gzip for reading compressed files\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "    data = []\n",
    "    with gzip.open(path, 'rt', encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            data.append(json.loads(l.strip()))\n",
    "        return(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Meta Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>No white background! It’s clear!</td>\n",
       "      <td>I bought this bc I thought it had the nice whi...</td>\n",
       "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
       "      <td>B08L6L3X1S</td>\n",
       "      <td>B08L6L3X1S</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1612044451196</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Awesome!  Great price!  Works well!</td>\n",
       "      <td>Perfect. How pissed am I that I recently paid ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B079BPGF6C</td>\n",
       "      <td>B079BPGF6C</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "      <td>1534443517349</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Worked but took an hour to install</td>\n",
       "      <td>Overall very happy with the end result. If you...</td>\n",
       "      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n",
       "      <td>B088DR7Z5B</td>\n",
       "      <td>B0BBGGC8F2</td>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>1629235304798</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                title  \\\n",
       "0     4.0     No white background! It’s clear!   \n",
       "1     5.0  Awesome!  Great price!  Works well!   \n",
       "2     5.0   Worked but took an hour to install   \n",
       "\n",
       "                                                text  \\\n",
       "0  I bought this bc I thought it had the nice whi...   \n",
       "1  Perfect. How pissed am I that I recently paid ...   \n",
       "2  Overall very happy with the end result. If you...   \n",
       "\n",
       "                                              images        asin parent_asin  \\\n",
       "0  [{'small_image_url': 'https://images-na.ssl-im...  B08L6L3X1S  B08L6L3X1S   \n",
       "1                                                 []  B079BPGF6C  B079BPGF6C   \n",
       "2  [{'small_image_url': 'https://m.media-amazon.c...  B088DR7Z5B  B0BBGGC8F2   \n",
       "\n",
       "                        user_id      timestamp  helpful_vote  \\\n",
       "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1612044451196             0   \n",
       "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1534443517349             2   \n",
       "2  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  1629235304798             3   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_review_cellPhones = './Cell_Phones_and_Accessories.jsonl.gz'\n",
    "data_review_raw_cellPhones = parse(path_review_cellPhones)\n",
    "df_review_raw_cellPhones = pd.DataFrame.from_dict(data_review_raw_cellPhones)\n",
    "df_review_raw_cellPhones.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA CLEANING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding numnber of reviews\n",
    "reviews_for_cellPhones = df_review_cellPhones.loc[df_review_cellPhones['asin'].isin(Cell_Phones_df.asin.unique())]\n",
    "df_asin_numReviews = pd.DataFrame()\n",
    "df_asin_numReviews['asin'] = reviews_for_cellPhones.groupby(by=\"asin\").count()[['reviewText']].index\n",
    "df_asin_numReviews['num_reviews'] = reviews_for_cellPhones.groupby(by=\"asin\").count()[['reviewText']].reviewText.values\n",
    "\n",
    "metaData_for_cellPhones = Cell_Phones_df.merge(df_asin_numReviews, on='asin', how='outer')\n",
    "metaData_for_cellPhones.fillna(value=0, inplace=True)\n",
    "\n",
    "metaData_for_cellPhones.head(3)\n",
    "\n",
    "with open('./metaData_for_cellPhones.pkl', 'wb') as fp:\n",
    "    pickle.dump(metaData_for_cellPhones, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_process(text):\n",
    "    cleaned_text = text.replace(\"\\n\\n\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"\\n\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"#\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"*\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"+\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"\\'\", \"'\")\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \" \")\n",
    "    cleaned_text = cleaned_text.replace(\"--\", \" \")\n",
    "    \n",
    "    cleaned_text = re.sub(r\"blogs.blackberry.com\\S+\", \" \", cleaned_text)\n",
    "    cleaned_text = re.sub(r\"helpblog.blackberry.com\\S+\", \" \", cleaned_text)\n",
    "    \n",
    "    # Remove repeated letters\n",
    "    cleaned_text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(cleaned_text))\n",
    "    \n",
    "    clean_tags = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleaned_text = re.sub(clean_tags, \" \", cleaned_text)\n",
    "\n",
    "    clean_urls =re.compile(r'https?://\\S+')\n",
    "    cleaned_text = re.sub(clean_urls, \" \", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\"=\", \" \")\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Vahid: Could we use the columns:Summary and Voting, somehow?\n",
    "reviews_for_cellPhones_df = df_review_raw_cellPhones.loc[df_review_raw_cellPhones['asin'].isin(Cell_Phones_df.asin.unique())]\n",
    "reviews_for_cellPhones_df = reviews_for_cellPhones_df.dropna(axis=0, subset=['reviewText'])\n",
    "\n",
    "# Clean reviews and create a text file for all reviews\n",
    "cellPhone_reviews = reviews_for_cellPhones_df.reviewText\n",
    "cellPhone_reviews_cleaned = cellPhone_reviews.apply(cleaning_process)\n",
    "\n",
    "reviews_for_cellPhones_df_cleaned = reviews_for_cellPhones_df.copy()\n",
    "reviews_for_cellPhones_df_cleaned['reviewText'] = cellPhone_reviews_cleaned.values\n",
    "\n",
    "wholeReview_reviews_for_cellPhones_df = pd.DataFrame()\n",
    "wholeReview_reviews_for_cellPhones_df['Index'] = reviews_for_cellPhones_df_cleaned[['asin', 'reviewerID']].apply(lambda x: '_'.join(x), axis=1)\n",
    "wholeReview_reviews_for_cellPhones_df['reviewText'] = reviews_for_cellPhones_df_cleaned.reviewText.values\n",
    "wholeReview_reviews_for_cellPhones_df = wholeReview_reviews_for_cellPhones_df.dropna(axis=0, subset=['reviewText'])\n",
    "\n",
    "reviews_for_cellPhones_df_cleaned.to_csv(\"./reviews_for_cellPhones_df_cleaned.csv\")\n",
    "\n",
    "with open(\".../Data/GeneratedData/reviews_wholeReview.txt\", \"w\") as f:\n",
    "    for review in cellPhone_reviews_cleaned.values:\n",
    "        _ = f.write(review + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATING PREFERENCES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list = list(Cell_Phones_df.brand.unique())\n",
    "os_list = ['ios', 'android', 'windows', 'No']\n",
    "memory_list = ['2 GB', '4 GB', '8 GB', '16 GB', '32 GB', '64 GB', '128 GB', '256 GB', 'No']\n",
    "color_list = ['White', 'Silver', 'Black', 'Red', 'Gold', 'No']\n",
    "\n",
    "# Generate all possible combinations for the preferences\n",
    "all_c = list(itertools.product(brand_list, os_list, memory_list, color_list))\n",
    "all_combinations = []\n",
    "for i in all_c:\n",
    "    if i[1] == \"ios\":\n",
    "        if i[1] == \"apple\":\n",
    "            all_combinations.append(list(i))\n",
    "    else:\n",
    "        if i[1] != \"apple\":\n",
    "            all_combinations.append(list(i))\n",
    "            \n",
    "all_combinations_dict = {}\n",
    "for i, j in enumerate(all_combinations):\n",
    "    all_combinations_dict[str(i+1)] = {}\n",
    "    all_combinations_dict[str(i+1)][\"brand\"] = j[0]\n",
    "    all_combinations_dict[str(i+1)][\"os\"] = j[1]\n",
    "    all_combinations_dict[str(i+1)][\"color\"] = j[3]\n",
    "    all_combinations_dict[str(i+1)][\"memory\"] = j[2]\n",
    "\n",
    "for k,v in list(all_combinations_dict.items())[63:70]:\n",
    "    print(k,v)\n",
    "    \n",
    "len(all_combinations_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate conversations for the preferences\n",
    "conversation_dict_part_1 = {}\n",
    "for k1,v1 in list(all_combinations_dict.items()):\n",
    "    conversation_dict_part_1[\"Conv_#\" + str(k1)] = {}\n",
    "    Agent_1 = \"Hello, May I help you?\"\n",
    "    User_1 = \"Hi, I would like to buy a Cell Phone\"\n",
    "    conversation_dict_part_1[f\"Conv_#\" + str(k1)]['Agent_1'] = Agent_1\n",
    "    conversation_dict_part_1[\"Conv_#\" + str(k1)]['User_1'] = User_1\n",
    "    counter = 1\n",
    "    for k2, v2 in list(v1.items()):\n",
    "        counter += 1\n",
    "        Agent = f\"Any preference on {k2}?\"\n",
    "        User = v2\n",
    "        conversation_dict_part_1[\"Conv_#\" + str(k1)][f'Agent_{counter}'] = Agent\n",
    "        conversation_dict_part_1[\"Conv_#\" + str(k1)][f'User_{counter}'] = User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in list(conversation_dict_part_1.items())[50:55]:\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWholeWord(w):\n",
    "    return (re.compile(r'\\b({0})\\b'.format(w), flags=re.IGNORECASE).search)\n",
    "\n",
    "def rules_generator(preferences_dict, features):\n",
    "    rules = []\n",
    "    for k2, v2 in list(preferences_dict.items()):\n",
    "        if k2 != \"brand\" and v2 != \"No\":\n",
    "            rules.append(findWholeWord(str(v2))(features.lower()))\n",
    "    return(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve items for the preferences\n",
    "DF = Cell_Phones_df \n",
    "retrieved_items_dict = {}\n",
    "for k1, v1 in list(all_combinations_dict.items()):\n",
    "    list_retrieved_items_final = []\n",
    "    rules = []\n",
    "    brand_value = v1['brand']\n",
    "    if brand_value == \"No\":\n",
    "        df_retrieved_items_brand = DF\n",
    "    else:\n",
    "        df_retrieved_items_brand = DF[DF.brand == brand_value]\n",
    "    zipped = list(zip(df_retrieved_items_brand.asin.values, df_retrieved_items_brand.all_features.values))\n",
    "    list_retrieved_items_final = []\n",
    "    for index, features in zipped:\n",
    "        if features:\n",
    "            rules = rules_generator(v1, features)\n",
    "            if all(rules):\n",
    "                list_retrieved_items_final.append(index)\n",
    "\n",
    "    retrieved_items_dict[k1] = {}\n",
    "    retrieved_items_dict[k1]['preferences'] = v1\n",
    "    retrieved_items_dict[k1]['retrieved items'] = list_retrieved_items_final\n",
    "    \n",
    "with open('./retrieved_items_dict.json', 'w') as f:\n",
    "    json.dump(retrieved_items_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(retrieved_items_dict.items())[55:65]:\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# **PUNCTUATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Punctuation Restoration using Transformer Models:** [GitHub](https://github.com/xashru/punctuation-restoration)  [Paper](http://noisy-text.github.io/2020/pdf/2020.d200-1.18.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Go to this folder: punctuation-restoration**\n",
    "\n",
    "```cd ./punctuation-restoration```\n",
    "\n",
    "**2. Run the inference.py to create the file test_en_out.txt:**\n",
    "\n",
    "```python3 src/inference.py --pretrained-model=roberta-large --weight-path=roberta-large-en.pt --language=en --in-file=data/test_en.txt --out-file=data/test_en_out.txt``` \n",
    "\n",
    "**3. Copy the file test_en_out.txt to the spacy_tokenization folder and rename it:**\n",
    "\n",
    "```cp ./punctuation-restoration/data/test_en_out.txt ./spacy_tokenization/data/input/reviews_punct.txt``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./reviews_punct.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SENTENCE TOKENIZATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Go to this folder: spacy_tokenization**\n",
    "\n",
    "```cd ./spacy_tokenization```\n",
    "\n",
    "**2. Run the spacy_tokenization_punct.py:**\n",
    "\n",
    "```python3 spacy_tokenization_punct.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cellPhone_data_punct.json') as json_file:\n",
    "    cellPhone_data_punct = json.load(json_file)\n",
    "for i,j in list(cellPhone_data_punct.items())[:2]:\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_reviews_for_cellPhones = pd.read_csv('./punct_reviews_for_cellPhones.csv')\n",
    "punct_reviews_for_cellPhones.head(3)\n",
    "punct_reviews_for_cellPhones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellPhone_data_punct_json = pd.read_json('./cellPhone_data_punct.json')\n",
    "cellPhone_data_punct_json = cellPhone_data_punct_json.T\n",
    "cellPhone_data_punct_json\n",
    "\n",
    "num_tokens = []\n",
    "for i in cellPhone_data_punct_json.label.values:\n",
    "    num_tokens.append(len(i))\n",
    "print(\"NUMBER OF REVIEWS:\", len(num_tokens))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.axes()\n",
    "ax.set_yscale('log')\n",
    "_ = plt.hist(num_tokens, bins='auto')\n",
    "\n",
    "print(\"AVERAGE OF NUM_TOKENS:\", np.mean(np.array(num_tokens)))\n",
    "\n",
    "max_length = 0\n",
    "for i in cellPhone_data_punct_json.label.values:\n",
    "    new_length = len(i)\n",
    "    if new_length > max_length:\n",
    "        max_length = new_length\n",
    "print(\"MAX_LENGTH:\", max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# **ASPECT EXTRACTION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improving BERT Performance for Aspect-based Sentiment Analysis:** [GitHub](https://github.com/IMPLabUniPr/BERT-for-ABSA/tree/H-SUM)  [Paper](https://arxiv.org/pdf/2010.11731.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Go to this folder: BERT-for-ABSA**\n",
    "\n",
    "```cd ./BERT-for-ABSA```\n",
    "\n",
    "**2. Copy the file: cellPhone_data_punct.json from spacy tokenization folder to BERT-for-ABSA:**\n",
    "\n",
    "```cp ./cellPhone_data_punct.json ./BERT-for-ABSA/ae/laptop/test.json```\n",
    "\n",
    "**3. Run the aspect extraction script:**\n",
    "\n",
    "```bash script/run_absa.sh ae laptop_pt laptop pt_ae 9 0```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOB_to_tokens(tags, tokens):\n",
    "    aspects = []\n",
    "    for idx , tag in enumerate(tags):\n",
    "        if tag == \"B\":\n",
    "            idx_B_start = idx + 1\n",
    "            token_B_start = tokens[idx]\n",
    "            for idx_ , tag_ in enumerate(tags[idx_B_start:]):\n",
    "                if tag_ == \"I\":\n",
    "                    idx_next = idx_B_start + idx_\n",
    "                    token_next = tokens[idx_next]\n",
    "                    token_B_start += \" \" + token_next\n",
    "                if tag_ == \"B\" or tag_ == \"O\" or idx_next == len(tags) - 1:\n",
    "                    aspects.append(str(token_B_start).replace(\"  \", \" \").strip())\n",
    "                    break\n",
    "            if idx_B_start == len(tags):\n",
    "                aspects.append(str(token_B_start).replace(\"  \", \" \").strip())\n",
    "        # E.g. tags = ['O', 'O', 'B', 'I', 'O', 'O', 'I', 'O']\n",
    "        if tag == \"I\":\n",
    "            if idx != 0:\n",
    "                idx_I_before = idx - 1\n",
    "                if tags[idx_I_before] == \"O\":\n",
    "                    aspects.append(tokens[idx])\n",
    "            else:\n",
    "                aspects.append(tokens[0])\n",
    "    return(aspects)\n",
    "\n",
    "def list_string_to_string(list_string):\n",
    "    review = ' '.join(list_string)\n",
    "    review = review.replace(\" ,\", \",\").replace(\" '\", \"'\").replace(\" .\", \".\")\n",
    "    review = review.replace(\" !\", \"!\").replace(\" ?\", \"?\").replace(\" :\", \":\")\n",
    "    review = review.replace(\" n't\", \"n't\").replace(\" 'm\", \"'m\")\n",
    "    return(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_predictions = \"./GeneratedData/\"\n",
    "path = path_to_predictions + \"predictions.json\"\n",
    "\n",
    "predictions_punct_df = pd.read_json(path)\n",
    "\n",
    "predictions_punct_df['Index'] = punct_reviews_for_cellPhones.Index.values\n",
    "predictions_punct_df['Length'] = predictions_punct_df.idx_map.apply(len)\n",
    "predictions_punct_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "print(\"Num_Reviews:\", len(predictions_punct_df[predictions_punct_df.Length > 100].Length.values))\n",
    "print(\"Max_length:\", max(predictions_punct_df[predictions_punct_df.Length > 100].Length.values))\n",
    "ax = plt.axes()\n",
    "ax.set_yscale('log')\n",
    "_ = plt.hist(predictions_punct_df[predictions_punct_df.Length > 100].Length.values, bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_100 = predictions_punct_df[predictions_punct_df.Length < 100]\n",
    "predictions_df_100 = predictions_df_100.reset_index(drop=True)\n",
    "\n",
    "y_pred=[]\n",
    "for ix, logit in enumerate(predictions_df_100[\"logits\"]):\n",
    "    pred=[0]*len(predictions_df_100[\"raw_X\"][ix])\n",
    "    #print(ix)\n",
    "    for jx, idx in enumerate(predictions_df_100[\"idx_map\"][ix]):\n",
    "        #print(jx)\n",
    "        lb=np.argmax(logit[jx])\n",
    "        if lb==1: #B\n",
    "            pred[idx]=1\n",
    "        elif lb==2: #I\n",
    "            if pred[idx]==0: #only when O->I (I->I and B->I ignored)\n",
    "                pred[idx]=2\n",
    "    y_pred.append(pred)\n",
    "\n",
    "mapping = {0: \"O\", 1:\"B\", 2:\"I\"}\n",
    "IOB_y_pred = []\n",
    "for pred_list in y_pred:\n",
    "    IOB_list = [mapping.get(item,item) for item in pred_list]\n",
    "    IOB_y_pred.append(IOB_list)\n",
    "\n",
    "predictions_df_100['tags'] = IOB_y_pred\n",
    "predictions_df_100.head()\n",
    "\n",
    "for i in range(1000):\n",
    "    idx = i\n",
    "    tags = predictions_df_100.tags.values[idx]\n",
    "    tokens = predictions_df_100.raw_X.values[idx]\n",
    "    _ = IOB_to_tokens(tags, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_aspect_df = pd.DataFrame()\n",
    "punct_aspect_df['Index'] = predictions_df_100.Index.values\n",
    "\n",
    "# convert list of strings to string\n",
    "punct_aspect_df['Review'] = predictions_df_100.raw_X.apply(list_string_to_string).values\n",
    "\n",
    "# convert tags to tokens\n",
    "punct_aspect_df['Aspect'] = predictions_df_100.apply(lambda x: IOB_to_tokens(x.tags, x.raw_X), axis=1).values\n",
    "\n",
    "punct_aspect_df.to_json(\"./punct_aspect_df.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_aspect_json_df = pd.read_json(\"./punct_aspect_df.json\")\n",
    "punct_aspect_json_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "# **ASPECT-BASED SENTIMENT ANALYSIS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LCF: A Local Context Focus Mechanism for Aspect-Based Sentiment Classification:** [GitHub](https://github.com/songyouwei/ABSA-PyTorch)  [Paper](https://www.proquest.com/openview/a1a719bc40fffafe8c7546382a4a4d68/1?pq-origsite=gscholar&cbl=2032433)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Go to this folder: ABSA-PyTorch**\n",
    "\n",
    "```cd ./ABSA-PyTorch```\n",
    "\n",
    "**2. Run the aspect-based sentiment analysis script:**\n",
    "\n",
    "```python3 absa.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_aspect_sentiment_json_df = pd.read_json(\"./punct_aspect_sentiment_df.json\")\n",
    "punct_aspect_sentiment_json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_extracted_aspects = []\n",
    "for idx, row in punct_aspect_sentiment_json_df.iterrows():\n",
    "    aspect_list = row['Aspect']\n",
    "    for aspect in aspect_list:\n",
    "        all_extracted_aspects.append(str(aspect).lower())\n",
    "all_extracted_aspects[:10]\n",
    "\n",
    "with open('./Cellphone_all_extracted_aspects.pkl', 'wb') as fp:\n",
    "    pickle.dump(all_extracted_aspects, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "word_could_dict=Counter(all_extracted_aspects)\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate_from_frequencies(word_could_dict)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_frequency_sorted = {k: v for k, v in sorted(dict(word_could_dict).items(), key=lambda item: item[1], reverse=True)}\n",
    "aspect_frequency_df = pd.DataFrame()\n",
    "aspect_frequency_df[\"Aspect\"] = list(aspect_frequency_sorted.keys())\n",
    "aspect_frequency_df[\"Frequency\"] = list(aspect_frequency_sorted.values())\n",
    "print(\"Number of extracted aspects:\", aspect_frequency_df.shape[0])\n",
    "aspect_100 = aspect_frequency_df[aspect_frequency_df.Frequency > 99]\n",
    "aspect_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_100.Aspect.values\n",
    "len(aspect_100.Aspect.values)\n",
    "len(list(aspect_frequency_df[aspect_frequency_df.Frequency == 1].Aspect.values))\n",
    "list(aspect_frequency_df[aspect_frequency_df.Frequency == 1].Aspect.values)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_aspects(row_aspect):\n",
    "    valids = re.sub(r\"[^A-Za-z]+\", '', row_aspect)\n",
    "    \n",
    "    correct_aspects = [\"usb\", \"cpu\", \"app\", \"ram\", \"gps\", \"sim\", \"ui\", \"ios\", \"run\", \"pen\", \"lte\", \"ios\",\n",
    "                       \"mic\", \"sd\", \"os\", \"ask\", \"use\", \"gpu\", \"key\", \"fee\", \"cam\", \"pad\", \"nfc\",\n",
    "                       \"gui\", \"vpn\", \"pay\", \"pic\", \"map\", \"fan\", \"set\", \"win\", \"buy\", \"tpu\", \"mp3\", \"web\"]\n",
    "    \n",
    "    if len(valids) > 3 or valids in correct_aspects:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_aspects = aspect_frequency_df.Aspect.apply(filter_aspects)\n",
    "wrong_aspects_3 = list(aspect_frequency_df[~filtered_aspects].Aspect.values)\n",
    "\n",
    "with open('./wrong_aspects_3.pkl', 'wb') as fp:\n",
    "    pickle.dump(wrong_aspects_3, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_aspect_list = [['android', 'android os'],\n",
    "                       ['app', 'applications', 'apps', 'android apps'],\n",
    "                       ['battery', 'battery life', 'batteries'],\n",
    "                       ['build', 'build quality', 'built'],\n",
    "                       ['button', 'buttons'],\n",
    "                       ['camera', 'camera quality'],\n",
    "                       ['charge', 'charger', 'charges', 'charging'],\n",
    "                       ['color', 'colors'],\n",
    "                       ['cost', 'costs'],\n",
    "                       ['edge', 'edges'],\n",
    "                       ['feature', 'features'],\n",
    "                       ['front camera', 'front facing camera'],\n",
    "                       ['function', 'functionality', 'functions'],\n",
    "                       ['games', 'gaming'],\n",
    "                       ['internal memory', 'internal storage'],\n",
    "                       ['keyboard', 'keys'],\n",
    "                       ['memory', 'memory card'],\n",
    "                       ['operating system', 'os',],\n",
    "                       ['performance', 'performs'],\n",
    "                       ['power', 'power button'],\n",
    "                       ['price', 'price point', 'prices'],\n",
    "                       ['screen', 'screens'],\n",
    "                       ['micro sd card', 'microsd card', 'sd card', 'microsd slot'],\n",
    "                       ['set up', 'setup'],\n",
    "                       ['sim', 'sim card'],\n",
    "                       ['sound', 'sound quality'],\n",
    "                       ['speaker', 'speakerphone', 'speakers'],\n",
    "                       ['speed', 'speeds'],\n",
    "                       ['touch screen', 'touchscreen'],\n",
    "                       ['ui', 'user interface']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_filtered_100 = aspect_frequency_df[filtered_aspects][aspect_frequency_df[filtered_aspects].Frequency > 99]\n",
    "aspect_filtered_100_list = list(aspect_filtered_100[aspect_filtered_100.Frequency > 99].Aspect.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aspect_filtered_100_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_aspect = ['look', 'looks', 'google', 'runs', 'use', 'work', 'works']\n",
    "wrong_aspects = wrong_aspects_3 + [\"lumia 1020\", \"zero key\", \"verizon\", 'back', 'edge', 'feel', 'phone', 'seller']\n",
    "final_aspect_100_list = [aspect for aspect in aspect_filtered_100_list if aspect not in wrong_aspects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = {0: 'Negative', 1: \"Neutral\", 2: 'Positive', -999: ''}\n",
    "def sentiment_aspect_dict(index, review, aspect_list, polarity_list, \n",
    "                          polarity_score_list, sentiments, final_aspect_100_list, polarity_treshold = 0.8):\n",
    "    absa_dictionary = {}    \n",
    "    if aspect_list:\n",
    "        for counter, aspect in enumerate(aspect_list):\n",
    "            if aspect in final_aspect_100_list:\n",
    "                polarity_scores = polarity_score_list[counter][0]\n",
    "                if max(polarity_scores) >= polarity_treshold:\n",
    "                    new_index = str(index) + \"_\" + str(counter)\n",
    "                    absa_dictionary[(new_index, aspect)] = {}\n",
    "                    absa_dictionary[(new_index, aspect)]['review'] = review\n",
    "                    polarity_idx = polarity_list[counter][0]\n",
    "                    absa_dictionary[(new_index, aspect)]['polarity'] = sentiments[polarity_idx]\n",
    "                    polarity_scores = polarity_score_list[counter][0]\n",
    "                    absa_dictionary[(new_index, aspect)]['polarity_scores'] = polarity_scores\n",
    "    return(absa_dictionary)\n",
    "\n",
    "sentiment_aspect_dict_all = {}\n",
    "for idx, row in punct_aspect_sentiment_json_df.iterrows():\n",
    "    if idx%1000 == 0:\n",
    "        print(idx)\n",
    "    all_index_list = row['Index'].split(\"_\")\n",
    "    item = str(all_index_list[0])\n",
    "    \n",
    "    index = row['Index'] \n",
    "    review = row['Review']\n",
    "    aspect_list = row['Aspect']\n",
    "    polarity_list = row['Polarity']\n",
    "    polarity_score_list = row['Polarity_score']\n",
    "    \n",
    "    absa_dict_result = sentiment_aspect_dict(index, review, aspect_list, polarity_list, \n",
    "                                             polarity_score_list, sentiments, final_aspect_100_list, polarity_treshold = 0.8)\n",
    "    if absa_dict_result:\n",
    "        if item not in sentiment_aspect_dict_all:\n",
    "            sentiment_aspect_dict_all[item] = []\n",
    "            sentiment_aspect_dict_list = sentiment_aspect_dict_all[item]\n",
    "            sentiment_aspect_dict_list.append(absa_dict_result)\n",
    "        else:\n",
    "            sentiment_aspect_dict_list = sentiment_aspect_dict_all[item]\n",
    "            sentiment_aspect_dict_list.append(absa_dict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Cellphone_similar_aspect_list_100.pkl', 'wb') as fp:\n",
    "    pickle.dump(similar_aspect_list, fp, protocol=4)\n",
    "    \n",
    "with open('./Cellphone_sentiment_aspect_dict_100.pkl', 'wb') as fp:\n",
    "    pickle.dump(sentiment_aspect_dict_all, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATING QA & OP PAIRS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab = pd.read_pickle(\"./english_vocab.pkl\")\n",
    "stop_words = pd.read_pickle(\"./stop_words.pkl\")\n",
    "wrong_aspects_3 = pd.read_pickle('./wrong_aspects_3.pkl')\n",
    "metaData_for_cellPhones = pd.read_pickle(\"./metaData_for_cellPhones.pkl\")\n",
    "dict_AspectSentiment = pd.read_pickle('./Cellphone_sentiment_aspect_dict_100.pkl')\n",
    "\n",
    "with open(\".../Data/GeneratedData/retrieved_items_dict.json\") as f:\n",
    "    retrieved_items_dict = json.load(f)\n",
    "\n",
    "wrong_aspects = wrong_aspects_3 + [\"lumia 1020\", \"zero key\", \"verizon\", 'back', 'edge', 'feel', 'phone', 'seller']\n",
    "\n",
    "correct_forms = ['bluetooth']\n",
    "\n",
    "Q1A_list = [\"What do you think about its {}?\", \"May I know your opinion on its {}?\",\n",
    "            \"What about its {}?\", \"Do you have any views on its {}?\",\n",
    "            \"Could you tell me your opinion on its {}?\",\n",
    "            \"Do you have any opinions about its {}?\", \"In your honest opinion, how is its {}?\",\n",
    "            \"Can you give me your thoughts on its {}?\", \"I’d like to know your views on its {}.\",\n",
    "            \"Do you have any particular views on its {}?\", \"From your point of view, how is the {}?\",\n",
    "            \"I’d be very interested to know your views on its {}.\"\n",
    "           ]\n",
    "\n",
    "Oneg1A_list = [\"I heard about its {} that \",\n",
    "               \"I was told by one of my friends about its {} that \",\n",
    "               \"As far as I know about its {}, \",\n",
    "               \"What I know about its {} is that \"]\n",
    "\n",
    "Opos1A_list = [\"No, I don't think so, because \",\n",
    "               \"Let me disagree with you, because \",\n",
    "               \"I see your point, but \",\n",
    "               \"I see what you mean, but \"]\n",
    "\n",
    "# For MultiWOZ\n",
    "#Opos1B_list = [\"If {} is important for you, we can offer this item. \", \n",
    "#               \"If {} is a crucial feature for you, we have this item. \"]\n",
    "\n",
    "Opos1B_list = [\"If {} is important for you, we can offer this item: {} \", \n",
    "               \"If {} is a crucial feature for you, we have this item: {} \"]\n",
    "\n",
    "Opos2A_list = [\"I can see what you’re saying but I disagree with you on its {} and even I can tell you something interesting about this phone and its {} that \",\n",
    "               \"I’m sorry but I don’t think so, specially about its {} and I would mention something about the {} of this phone that \"]\n",
    "\n",
    "# For MultiWOZ\n",
    "#Opos1B1_list = [\"I heard about this phone and specially its {} that \",\n",
    "#               \"I was told by one of my friends about this phone and its {} that \",\n",
    "#               \"I was wondering if you have this phone, it might be a good choice because as far as I know about its {}, \"]\n",
    "\n",
    "Opos1B1_list = [\"I heard about this phone {} and specially its {} that \",\n",
    "                \"I was told by one of my friends about this phone {} and its {} that \",\n",
    "                \"I was wondering if you have this phone {}, it might be a good choice because as far as I know about its {}, \"]\n",
    "\n",
    "Opos1B2_list = [\"Yes, it's true! This phone is also a good choice.\",\n",
    "                \"Yes, That's so true. This phone is also a good choice.\",\n",
    "                \"Yes, That's for sure. This phone is also a good choice.\",\n",
    "                \"Yes, I think so too. This phone is also a good choice.\",\n",
    "                \"Yes, That is what I think too. This phone is also a good choice.\",\n",
    "                \"Yes! I agree with you. This phone is also a good choice.\",\n",
    "                \"Yes, I agree with you about it. This phone is also a good choice.\",\n",
    "                \"Yes, That's exactly what I know about it. This phone is also a good choice.\"]\n",
    "\n",
    "Opos2B_list = [\"Yes, it's true! This phone is also a good choice and even I can tell you something interesting about this phone and its {} that \",\n",
    "               \"Yes, That's so true. This phone is also a good choice and I would mention something about the {} of this phone that \",\n",
    "               \"Yes, That's for sure. This phone is also a good choice and even I can tell you something interesting about this phone and its {} that \",\n",
    "               \"Yes, I think so too. This phone is also a good choice and I would mention something about the {} of this phone that \",\n",
    "               \"Yes, That is what I think too. This phone is also a good choice and even I can tell you something interesting about this phone and its {} that \",\n",
    "               \"Yes! I agree with you. This phone is also a good choice and I would mention something about the {} of this phone that \",\n",
    "               \"Yes, I agree with you about it. This phone is also a good choice and even I can tell you something interesting about this phone and its {} that \",\n",
    "               \"Yes, That's exactly what I know about it. This phone is also a good choice and I would mention something about the {} of this phone that \"]\n",
    "\n",
    "Oneg2B_list = [\"Yes, it's true! This phone might be a good choice but you should know about its {} that \",\n",
    "               \"Yes, That's so true. This phone can be also a good choice but I should say about the {} of this phone that \",\n",
    "               \"Yes, That's for sure. This phone is also a good choice However about the {} of this phone I should say that \",\n",
    "               \"Yes, I completely agree with you. This phone might be a good choice but you should know about its {} that \",\n",
    "               \"Yes, I totally agree with you. This phone can be also a good choice but I should say about the {} of this phone that \",\n",
    "               \"Yes! I agree with you. This phone is also a good choice However about the {} of this phone I should say that \",\n",
    "               \"Yes, I agree with you about it. This phone can be also a good choice but I should say about the {} of this phone that \",\n",
    "               \"Yes, That's exactly what I know about it. However I should say something about the {} of this phone that \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspects_similarity_check(aspect_1, aspect_2, similar_aspect_list):\n",
    "    check=False\n",
    "    for i in similar_aspect_list:\n",
    "        if aspect_1.lower() in i and aspect_2.lower() in i:\n",
    "            check=True\n",
    "            break\n",
    "    if check:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)\n",
    "\n",
    "def cleaning_aspect(aspect):\n",
    "    if aspect != None:\n",
    "        cleaned_aspect = aspect.replace(\"/\", \"\")\n",
    "        cleaned_aspect = re.sub(' +', ' ', cleaned_aspect)\n",
    "        cleaned_aspect = cleaned_aspect.strip()\n",
    "    else:\n",
    "        cleaned_aspect = aspect\n",
    "    return(cleaned_aspect)\n",
    "\n",
    "def cleaning_review(review):\n",
    "    if str(review).lower()[:3].strip() == \"but\":\n",
    "        cleaned_review = str(review)[3:].strip(\":\")\n",
    "        cleaned_review = cleaned_review.strip(\";\")\n",
    "        cleaned_review = cleaned_review.strip(\",\")\n",
    "        cleaned_review = cleaned_review.strip()\n",
    "    elif str(review).lower()[:3].strip() == \"and\":\n",
    "        cleaned_review = str(review)[3:].strip(\":\")\n",
    "        cleaned_review = cleaned_review.strip(\";\")\n",
    "        cleaned_review = cleaned_review.strip(\",\")\n",
    "        cleaned_review = cleaned_review.strip()\n",
    "    elif str(review).lower()[:4].strip() == \"then\":\n",
    "        cleaned_review = str(review)[4:].strip(\":\")\n",
    "        cleaned_review = cleaned_review.strip(\";\")\n",
    "        cleaned_review = cleaned_review.strip(\",\")\n",
    "        cleaned_review = cleaned_review.strip()\n",
    "    elif str(review).lower()[:9].strip() == \"otherwise\":\n",
    "        cleaned_review = str(review)[9:].strip(\":\")\n",
    "        cleaned_review = cleaned_review.strip(\";\")\n",
    "        cleaned_review = cleaned_review.strip(\",\")\n",
    "        cleaned_review = cleaned_review.strip()\n",
    "    else:\n",
    "        cleaned_review = review\n",
    "    return(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData_for_cellPhones = pd.read_pickle(\"./metaData_for_cellPhones.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qpos1A_Apos1A(item, wrong_aspects, correct_forms, Q11_list, dict_AspectSentiment):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        counter += 1\n",
    "                        aspect = cleaning_aspect(str(aspect))\n",
    "                        \n",
    "                        Qpos1A = random.choice(Q1A_list).format(aspect)\n",
    "                        Apos1A = review\n",
    "                        \n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)] = {}\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A'] = {}\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A']['Question'] = Qpos1A\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A']['Labels'] = {}\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A']['Labels']['Key'] = key\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A']['Labels']['Aspect'] = aspect\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Qpos1A']['Labels']['Polarity'] = str(polarity).lower()\n",
    "                        \n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A'] = {}\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A']['Answer'] = Apos1A\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A']['Labels'] = {}\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A']['Labels']['Key'] = key\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A']['Labels']['Aspect'] = aspect\n",
    "                        blocks[\"Qpos1A_Apos1A_\" + str(counter)]['Apos1A']['Labels']['Polarity'] = str(polarity).lower()\n",
    "    return(blocks)\n",
    "\n",
    "def Oneg1A_Opos1A(item, wrong_aspects, correct_forms, Oneg1A_list, Opos1A_list, dict_AspectSentiment):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    aspect_review_polarity_key_list = []\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        aspect_review_polarity_key_list.append((aspect, review, polarity, key))\n",
    "\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect != None and aspect not in wrong_aspects:\n",
    "                    if str(polarity).lower() == 'negative':\n",
    "                        sentence_aspect = review\n",
    "                        \n",
    "                        Oneg1A = random.choice(Oneg1A_list).format(aspect) + sentence_aspect\n",
    "                        \n",
    "                        for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                            aspect_ = cleaning_aspect(aspect_)\n",
    "                                \n",
    "                            if str(polarity_).lower() == 'positive' and np.logical_or(str(aspect) == str(aspect_), aspects_similarity_check(aspect, aspect_, similar_aspect_list)):\n",
    "                                counter += 1\n",
    "                                sentence_aspect_ = review_\n",
    "\n",
    "                                Opos1A = random.choice(Opos1A_list) + sentence_aspect_\n",
    "\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)] = {}\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A'] = {}\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A']['Opinion'] = Oneg1A\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A']['Labels'] = {}\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A']['Labels']['Key'] = key\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A']['Labels']['Aspect'] = aspect\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Oneg1A']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A'] = {}\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A']['Opinion'] = Opos1A\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A']['Labels'] = {}\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A']['Labels']['Key'] = key_\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A']['Labels']['Aspect'] = aspect_\n",
    "                                blocks[\"Oneg1A_Opos1A_\" + str(counter)]['Opos1A']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "    return(blocks)\n",
    "\n",
    "def Oneg1A_Opos1B(item, retrieved_items, wrong_aspects, correct_forms, Oneg1A_list, Opos1B_list, dict_AspectSentiment, DF, retrieved=True, also_view=False):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    item_1 = item\n",
    "    if retrieved:\n",
    "        other_items_list = [i for i in retrieved_items if i != item_1]\n",
    "    elif also_view:\n",
    "        if DF.query(\"asin == @item_1\").also_view.values.size > 0:\n",
    "            other_items_list = DF.query(\"asin == @item_1\").also_view.values[0]\n",
    "        else:\n",
    "            other_items_list = None\n",
    "    if other_items_list:\n",
    "        aspect_review_polarity_key_lists = []\n",
    "        for item_2 in other_items_list:\n",
    "            item_2_review_list = dict_AspectSentiment.get(item_2)\n",
    "            if item_2_review_list:\n",
    "                aspect_review_polarity_key_list = []\n",
    "                for item_2_review_dict in item_2_review_list:\n",
    "                    for item_2_reviewer_aspect_key, item_2_review_sentiment in (item_2_review_dict.items()):\n",
    "                        item_2_key = item_2_reviewer_aspect_key[0]\n",
    "                        item_2_aspect = item_2_reviewer_aspect_key[1]\n",
    "                        item_2_aspect = cleaning_aspect(item_2_aspect)\n",
    "                        item_2_review = item_2_review_sentiment['review']\n",
    "                        item_2_review = cleaning_review(item_2_review)\n",
    "                        item_2_polarity = item_2_review_sentiment['polarity']\n",
    "                        if item_2_aspect not in wrong_aspects and item_2_aspect != None:\n",
    "                            if str(item_2_polarity).lower() == 'positive':\n",
    "                                aspect_review_polarity_key_list.append((item_2, item_2_aspect, item_2_review, item_2_polarity, item_2_key))\n",
    "\n",
    "                aspect_review_polarity_key_lists.append(aspect_review_polarity_key_list)\n",
    "\n",
    "\n",
    "        item_1_review_list = dict_AspectSentiment.get(item_1)\n",
    "        if item_1_review_list:\n",
    "            for item_1_review_dict in item_1_review_list:\n",
    "                for item_1_reviewer_aspect_key, item_1_review_sentiment in (item_1_review_dict.items()):\n",
    "                    item_1_key = item_1_reviewer_aspect_key[0]\n",
    "                    item_1_aspect = item_1_reviewer_aspect_key[1]\n",
    "                    item_1_aspect = cleaning_aspect(item_1_aspect)\n",
    "                    item_1_review = item_1_review_sentiment['review']\n",
    "                    item_1_review = cleaning_review(item_1_review)\n",
    "                    item_1_polarity = item_1_review_sentiment['polarity']\n",
    "                    if item_1_aspect != None and item_1_aspect not in wrong_aspects:\n",
    "                        if str(item_1_polarity).lower() == 'negative':\n",
    "                            Oneg1A = random.choice(Oneg1A_list).format(item_1_aspect) + item_1_review\n",
    "\n",
    "                            for item_aspect_review_polarity_key in aspect_review_polarity_key_lists:\n",
    "                                for item_, aspect_, review_, polarity_, key_ in item_aspect_review_polarity_key:\n",
    "                                    aspect_ = cleaning_aspect(aspect_)\n",
    "\n",
    "                                    if str(polarity_).lower() == 'positive' and np.logical_or(str(item_1_aspect) == str(aspect_), aspects_similarity_check(item_1_aspect, aspect_, similar_aspect_list)):\n",
    "                                        counter += 1\n",
    "                                        \n",
    "                                        \n",
    "                                        Opos1B = random.choice(Opos1B_list).format(item_1_aspect, item_) + review_\n",
    "                                        #For MultiWOZ\n",
    "                                        #Opos1B = random.choice(Opos1B_list).format(item_1_aspect) + review_\n",
    "\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)] = {}\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A']['Opinion'] = Oneg1A\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A']['Labels'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A']['Labels']['Key'] = item_1_key\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A']['Labels']['Aspect'] = item_1_aspect\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Oneg1A']['Labels']['Polarity'] = str(item_1_polarity).lower()\n",
    "\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B']['Opinion'] = Opos1B\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B']['Labels'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B']['Labels']['Key'] = key_\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B']['Labels']['Aspect'] = aspect_\n",
    "                                        blocks[\"Oneg1A_Opos1B_\" + str(counter)]['Opos1B']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "                                    \n",
    "    return(blocks)\n",
    "\n",
    "def Oneg1A_Opos2A(item, wrong_aspects, correct_forms, Oneg1A_list, Opos2A_list, dict_AspectSentiment, restricted_version=True):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    aspect_review_polarity_key_list = []\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        aspect_review_polarity_key_list.append((aspect, review, polarity, key))\n",
    "\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect != None and aspect not in wrong_aspects:\n",
    "                    if str(polarity).lower() == 'negative':\n",
    "                        \n",
    "                        Oneg1A = random.choice(Oneg1A_list).format(aspect) + review\n",
    "                        \n",
    "                        check = False \n",
    "                        # We disagree with the user only when there is a positive review for the aspect, mentioned by user\n",
    "                        if restricted_version == True:\n",
    "                            for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                                if check == False:\n",
    "                                    aspect_ = cleaning_aspect(aspect_)\n",
    "\n",
    "                                    if str(polarity_).lower() == 'positive' and np.logical_or(str(aspect) == str(aspect_), aspects_similarity_check(aspect, aspect_, similar_aspect_list)):\n",
    "                                        check = True\n",
    "                                        break\n",
    "                            \n",
    "                            if check == True:\n",
    "                                for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                                    aspect_ = cleaning_aspect(aspect_)\n",
    "                                    if str(polarity_).lower() == 'positive':\n",
    "                                        counter += 1\n",
    "\n",
    "                                        Opos2A = random.choice(Opos2A_list).format(aspect, aspect_) + review_\n",
    "\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)] = {}\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Opinion'] = Oneg1A\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Key'] = key\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Aspect'] = aspect\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Opinion'] = Opos2A\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels'] = {}\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Key'] = key_\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Aspect'] = aspect_\n",
    "                                        blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "                        \n",
    "                        else:\n",
    "                            for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                                aspect_ = cleaning_aspect(aspect_)\n",
    "                                if str(polarity_).lower() == 'positive':\n",
    "                                    counter += 1\n",
    "\n",
    "                                    Opos2A = random.choice(Opos2A_list).format(aspect, aspect_) + review_\n",
    "\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)] = {}\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A'] = {}\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Opinion'] = Oneg1A\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels'] = {}\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Key'] = key\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Aspect'] = aspect\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Oneg1A']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A'] = {}\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Opinion'] = Opos2A\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels'] = {}\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Key'] = key_\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Aspect'] = aspect_\n",
    "                                    blocks[\"Oneg1A_Opos2A_\" + str(counter)]['Opos2A']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "                                    \n",
    "    return(blocks)\n",
    "\n",
    "\n",
    "done_items_neg = []\n",
    "all_blocks_neg = {}\n",
    "\n",
    "for index in list(retrieved_items_dict.keys()):\n",
    "    print(str(index))\n",
    "    retrieved_items_1 = retrieved_items_dict[str(index)].get(\"retrieved items\")\n",
    "    retrieved_items_with_review = [i for i in retrieved_items_1 if metaData_for_cellPhones.query(\"asin == @i\").num_reviews.values[0] > 0]\n",
    "    print('retrieved_items_with_review:', retrieved_items_with_review)\n",
    "    if len(retrieved_items_with_review) > 0:\n",
    "        for item in retrieved_items_with_review:\n",
    "            if item not in done_items_neg:\n",
    "                done_items_neg.append(item)\n",
    "                print(item)\n",
    "                all_blocks_neg[str(item)] = {}\n",
    "                blocks_Qpos1A_Apos1A = Qpos1A_Apos1A(item, wrong_aspects, correct_forms, Q1A_list, dict_AspectSentiment)\n",
    "                all_blocks_neg[str(item)]['Qpos1A_Apos1A'] = blocks_Qpos1A_Apos1A\n",
    "                print(\"blocks_Qpos1A_Apos1A is DONE!\")\n",
    "                \n",
    "                blocks_Oneg1A_Opos1A = Oneg1A_Opos1A(item, wrong_aspects, correct_forms, Oneg1A_list, Opos1A_list, dict_AspectSentiment)\n",
    "                all_blocks_neg[str(item)]['Oneg1A_Opos1A'] = blocks_Oneg1A_Opos1A\n",
    "                print(\"blocks_Oneg1A_Opos1A is DONE!\")\n",
    "\n",
    "                blocks_Oneg1A_Opos1B_retrieved = Oneg1A_Opos1B(item, retrieved_items_with_review, wrong_aspects, correct_forms, Oneg1A_list, Opos1B_list,\n",
    "                                                     dict_AspectSentiment, metaData_for_cellPhones, retrieved=True, also_view=False)\n",
    "                all_blocks_neg[str(item)]['Oneg1A_Opos1B_retrieved'] = blocks_Oneg1A_Opos1B_retrieved\n",
    "                print(\"blocks_Oneg1A_Opos1B_retrieved is DONE!\")\n",
    "\n",
    "                blocks_Oneg1A_Opos1B_also_view = Oneg1A_Opos1B(item, retrieved_items_with_review, wrong_aspects, correct_forms, Oneg1A_list, Opos1B_list,\n",
    "                                                     dict_AspectSentiment, metaData_for_cellPhones, retrieved=False, also_view=True)\n",
    "                all_blocks_neg[str(item)]['Oneg1A_Opos1B_also_view'] = blocks_Oneg1A_Opos1B_also_view\n",
    "                print(\"blocks_Oneg1A_Opos1B_also_view is DONE!\")\n",
    "\n",
    "                blocks_Oneg1A_Opos2A_restricted = Oneg1A_Opos2A(item, wrong_aspects, correct_forms, Oneg1A_list, Opos2A_list,\n",
    "                                                    dict_AspectSentiment, restricted_version=True)\n",
    "                all_blocks_neg[str(item)]['Oneg1A_Opos2A_restricted'] = blocks_Oneg1A_Opos2A_restricted\n",
    "                print(\"blocks_Oneg1A_Opos2A_restricted is DONE!\")\n",
    "                \n",
    "                blocks_Oneg1A_Opos2A_unrestricted = Oneg1A_Opos2A(item, wrong_aspects, correct_forms, Oneg1A_list, Opos2A_list,\n",
    "                                                                  dict_AspectSentiment, restricted_version=False)\n",
    "                all_blocks_neg[str(item)]['Oneg1A_Opos2A_unrestricted'] = blocks_Oneg1A_Opos2A_unrestricted\n",
    "                print(\"blocks_Oneg1A_Opos2A_unrestricted is DONE!\")\n",
    "\n",
    "with open('./100_blocks_neg.json', 'w') as f:\n",
    "    json.dump(all_blocks_neg, f)\n",
    "\n",
    "with open('./done_items_neg.pkl', 'wb') as fp:\n",
    "    pickle.dump(done_items_neg, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Opos1B_Opos2B(item, wrong_aspects, correct_forms, Opos1B1_list, Opos2B_list, dict_AspectSentiment):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    aspect_review_polarity_key_list = []\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        aspect_review_polarity_key_list.append((aspect, review, polarity, key))\n",
    "                        \n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect != None and aspect not in wrong_aspects:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        \n",
    "                        sentence_aspect = review\n",
    "                        \n",
    "                        #For MultiWOZ\n",
    "                        #Opos1B = random.choice(Opos1B1_list).format(aspect) + sentence_aspect\n",
    "                        Opos1B = random.choice(Opos1B1_list).format(item, aspect) + sentence_aspect\n",
    "    \n",
    "                        for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                            aspect_ = cleaning_aspect(aspect_)\n",
    "                            if str(polarity_).lower() == 'positive' and str(review) != str(review_):\n",
    "                                counter += 1\n",
    "\n",
    "                                sentence_aspect_ = review_\n",
    "\n",
    "                                Opos2B = random.choice(Opos2B_list).format(aspect_) + sentence_aspect_\n",
    "\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)] = {}\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B'] = {}\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B']['Opinion'] = Opos1B\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B']['Labels'] = {}\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B']['Labels']['Key'] = key\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B']['Labels']['Aspect'] = aspect\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos1B']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B'] = {}\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B']['Opinion'] = Opos2B\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B']['Labels'] = {}\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B']['Labels']['Key'] = key_\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B']['Labels']['Aspect'] = aspect_\n",
    "                                blocks[\"Opos1B_Opos2B_\" + str(counter)]['Opos2B']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "    return(blocks)\n",
    "\n",
    "def Opos1B_Opos1B2(item, wrong_aspects, correct_forms, Opos1B1_list, Opos1B2_list,\n",
    "                  dict_AspectSentiment, only_agreement=True, agreement_and_more=True):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    aspect_review_polarity_key_list = []\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list and agreement_and_more:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        aspect_review_polarity_key_list.append((aspect, review, polarity, key))\n",
    "                        \n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect != None and aspect not in wrong_aspects:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        \n",
    "                        #For MultiWOZ\n",
    "                        #Opos1B = random.choice(Opos1B1_list).format(aspect) + sentence_aspect\n",
    "                        Opos1B = random.choice(Opos1B1_list).format(item, aspect) + review\n",
    "                        \n",
    "                        if only_agreement:\n",
    "                            counter += 1\n",
    "                            \n",
    "                            Opos1B2 = random.choice(Opos1B2_list)\n",
    "                            \n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)] = {}\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B'] = {}\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Opinion'] = Opos1B\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels'] = {}\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Key'] = key\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Aspect'] = aspect\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2'] = {}\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Opinion'] = Opos1B2\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels'] = {}\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Key'] = key\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Aspect'] = aspect\n",
    "                            blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Polarity'] = str(polarity).lower()\n",
    "                            \n",
    "                        elif agreement_and_more:\n",
    "                            \n",
    "                            for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                                aspect_ = cleaning_aspect(aspect_)\n",
    "\n",
    "                                if np.logical_or(aspect == aspect_, aspects_similarity_check(aspect, aspect_, similar_aspect_list)) and str(review_) != str(review):  \n",
    "                                    counter += 1\n",
    "\n",
    "                                    Opos1B2 = random.choice(Opos1B2_list) + \" \" + review_\n",
    "\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)] = {}\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B'] = {}\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Opinion'] = Opos1B\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels'] = {}\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Key'] = key\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Aspect'] = aspect\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2'] = {}\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Opinion'] = Opos1B2\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels'] = {}\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Key'] = key_\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Aspect'] = aspect_\n",
    "                                    blocks[\"Opos1B_Opos1B2_\" + str(counter)]['Opos1B2']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "    return(blocks)\n",
    "\n",
    "def Opos1B_Oneg2B(item, wrong_aspects, correct_forms, Opos1B1_list, Oneg2B_list, dict_AspectSentiment):\n",
    "    blocks = {}\n",
    "    counter = 0\n",
    "    similarity = 0\n",
    "    aspect_review_polarity_key_list = []\n",
    "    item_review_list = dict_AspectSentiment.get(item)\n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect not in wrong_aspects and aspect != None:\n",
    "                    if str(polarity).lower() == 'negative':\n",
    "                        aspect_review_polarity_key_list.append((aspect, review, polarity, key))\n",
    "                        \n",
    "    if item_review_list:\n",
    "        for review_dict in item_review_list:\n",
    "            for item_reviewer_aspect_key, review_sentiment in (review_dict.items()):\n",
    "                key = item_reviewer_aspect_key[0]\n",
    "                aspect = item_reviewer_aspect_key[1]\n",
    "                aspect = cleaning_aspect(aspect)\n",
    "                review = review_sentiment['review']\n",
    "                review = cleaning_review(review)\n",
    "                polarity = review_sentiment['polarity']\n",
    "                if aspect != None and aspect not in wrong_aspects:\n",
    "                    if str(polarity).lower() == 'positive':\n",
    "                        \n",
    "                        #For MultiWOZ\n",
    "                        #Opos1B = random.choice(Opos1B1_list).format(aspect) + sentence_aspect\n",
    "                        Opos1B = random.choice(Opos1B1_list).format(item, aspect) + review\n",
    "    \n",
    "                        for aspect_, review_, polarity_, key_ in aspect_review_polarity_key_list:\n",
    "                            aspect_ = cleaning_aspect(aspect_)\n",
    "\n",
    "                            if str(polarity_).lower() == 'negative' and str(review) != str(review_): \n",
    "                                counter += 1\n",
    "\n",
    "                                Oneg2B = random.choice(Oneg2B_list).format(aspect_) + review_\n",
    "\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)] = {}\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B'] = {}\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B']['Opinion'] = Opos1B\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B']['Labels'] = {}\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B']['Labels']['Key'] = key\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B']['Labels']['Aspect'] = aspect\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Opos1B']['Labels']['Polarity'] = str(polarity).lower()\n",
    "\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B'] = {}\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B']['Opinion'] = Oneg2B\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B']['Labels'] = {}\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B']['Labels']['Key'] = key_\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B']['Labels']['Aspect'] = aspect_\n",
    "                                blocks[\"Opos1B_Oneg2B_\" + str(counter)]['Oneg2B']['Labels']['Polarity'] = str(polarity_).lower()\n",
    "    return(blocks)\n",
    "\n",
    "done_items_pos = []\n",
    "all_blocks_pos = {}\n",
    "for index in list(retrieved_items_dict.keys()):\n",
    "    print(str(index))\n",
    "    retrieved_items_1 = retrieved_items_dict[str(index)].get(\"retrieved items\")\n",
    "    retrieved_items_with_review = [i for i in retrieved_items_1 if metaData_for_cellPhones.query(\"asin == @i\").num_reviews.values[0] > 0]\n",
    "    print('retrieved_items_with_review:', retrieved_items_with_review)\n",
    "    if len(retrieved_items_with_review) > 0:\n",
    "        for item in retrieved_items_with_review:\n",
    "            if item not in all_blocks_pos:\n",
    "                print(item)\n",
    "                done_items_pos.append(item)\n",
    "                all_blocks_pos[str(item)] = {}               \n",
    "                blocks_Opos1B_Opos1B2_only_agreement = Opos1B_Opos1B2(item, wrong_aspects, correct_forms, Opos1B1_list, Opos1B2_list,\n",
    "                                                          dict_AspectSentiment, only_agreement=True, agreement_and_more=False)\n",
    "                all_blocks_pos[str(item)]['Opos1B_Opos1B2_only_agreement'] = blocks_Opos1B_Opos1B2_only_agreement\n",
    "                print(\"Opos1B_Opos1B2_only_agreement is DONE!\")\n",
    "\n",
    "                blocks_Opos1B_Opos1B2_agreement_and_more = Opos1B_Opos1B2(item, wrong_aspects, correct_forms, Opos1B1_list, Opos1B2_list,\n",
    "                                                                          dict_AspectSentiment, only_agreement=False, agreement_and_more=True)\n",
    "                all_blocks_pos[str(item)]['Opos1B_Opos1B2_agreement_and_more'] = blocks_Opos1B_Opos1B2_agreement_and_more\n",
    "                print(\"blocks_Opos1B_Opos1B2_agreement_and_more is DONE!\")\n",
    "\n",
    "                blocks_Opos1B_Opos2B = Opos1B_Opos2B(item, wrong_aspects, correct_forms, Opos1B1_list, Opos2B_list, dict_AspectSentiment)\n",
    "                all_blocks_pos[str(item)]['Opos1B_Opos2B'] = blocks_Opos1B_Opos2B\n",
    "                print(\"blocks_Opos1B_Opos2B is DONE!\")\n",
    "\n",
    "                blocks_Opos1B_Oneg2B = Opos1B_Oneg2B(item, wrong_aspects, correct_forms, Opos1B1_list, Oneg2B_list, dict_AspectSentiment)\n",
    "                all_blocks_pos[str(item)]['Opos1B_Oneg2B'] = blocks_Opos1B_Oneg2B\n",
    "                print(\"blocks_Opos1B_Oneg2B is DONE!\")\n",
    "\n",
    "with open('./100_blocks_pos.json', 'w') as f:\n",
    "    json.dump(all_blocks_pos, f)\n",
    "\n",
    "with open('./done_items_pos.pkl', 'wb') as fp:\n",
    "    pickle.dump(done_items_pos, fp, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GENERATING CONVERSATIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./100_blocks_neg.json') as f:\n",
    "    blocks_neg_100 = json.load(f)\n",
    "\n",
    "with open('./100_blocks_pos.json') as f:\n",
    "    blocks_pos_100 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./retrieved_items_dict.json\") as f:\n",
    "    retrieved_items_dict = json.load(f)\n",
    "    \n",
    "metaData_for_cellPhones = pd.read_pickle(\"./metaData_for_cellPhones.pkl\")\n",
    "\n",
    "all_items_with_review = []\n",
    "for index in list(retrieved_items_dict.keys()):\n",
    "    retrieved_items_1 = retrieved_items_dict[str(index)].get(\"retrieved items\")\n",
    "    retrieved_items_with_review = [i for i in retrieved_items_1 if metaData_for_cellPhones.query(\"asin == @i\").num_reviews.values[0] > 0]\n",
    "    all_items_with_review += retrieved_items_with_review\n",
    "    \n",
    "all_items_with_review = list(set(all_items_with_review))\n",
    "\n",
    "def find_retrieved_items_and_index(retrieved_items_dict, selected_item):\n",
    "    all_retrieved_index = []\n",
    "    all_retrieved_items = []\n",
    "    for index in range(1, len(retrieved_items_dict.keys())+1):\n",
    "        retrieved_items_list = retrieved_items_dict[str(index)].get(\"retrieved items\")\n",
    "        if selected_item in retrieved_items_list:\n",
    "            all_retrieved_index.append(index)\n",
    "            all_retrieved_items += retrieved_items_dict[str(index)].get(\"retrieved items\")\n",
    "    all_retrieved_items = list(set(all_retrieved_items))\n",
    "    return(all_retrieved_index, all_retrieved_items)\n",
    "\n",
    "def select_pairs_combination(all_pairs_combination, num_pairs):\n",
    "    selected_pairs_combination = []\n",
    "    if len(all_pairs_combination) > num_pairs:\n",
    "        for i in range(5):\n",
    "            random.shuffle(all_pairs_combination)\n",
    "        while len(selected_pairs_combination) < num_pairs:\n",
    "            selected_pair_combination = random.choice(all_pairs_combination)\n",
    "            if selected_pair_combination not in selected_pairs_combination:\n",
    "                selected_pairs_combination.append(selected_pair_combination)\n",
    "    else:\n",
    "        selected_pairs_combination = all_pairs_combination\n",
    "    return(selected_pairs_combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaction is separate from other utterences\n",
    "\n",
    "def conv_type_1(selected_item, num_pairs):\n",
    "    conv_dict_1 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "    all_pairs_list_NP_DISAGREEMENT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1A'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    all_pairs_combination = list(itertools.product(all_pairs_list_PP_QA, all_pairs_list_NP_DISAGREEMENT, all_pairs_list_PP_QA))\n",
    "    selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "    for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "        conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[0]]\n",
    "        tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "        conv_dict_1['conv_' + str(index + 1)]['pair_1'] = PP_QA\n",
    "\n",
    "        NP_DISAGREEMENT = blocks_neg_100[selected_item]['Oneg1A_Opos1A'][selected_pair[1]]\n",
    "        if NP_DISAGREEMENT['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and NP_DISAGREEMENT['Opos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"] \\\n",
    "        and NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Key'])\n",
    "            tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Key'])\n",
    "            tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'])\n",
    "            tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'])\n",
    "            conv_dict_1['conv_' + str(index + 1)]['pair_2'] = NP_DISAGREEMENT\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        REACTION = \"Ah, I see!\"\n",
    "        conv_dict_1['conv_' + str(index + 1)]['pair_3'] = REACTION\n",
    "\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[2]]\n",
    "        if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            \n",
    "            conv_dict_1['conv_' + str(index + 1)]['pair_4'] = PP_QA\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        DECISION = \"Okay! Great! I buy this!\"\n",
    "        conv_dict_1['conv_' + str(index + 1)]['pair_5'] = DECISION\n",
    "        tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "    \n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_1.keys()):\n",
    "        if conv_dict_1[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_1[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_1_test = conv_type_1(selected_item, num_pairs)\n",
    "conv_type_1_test['conv_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_1(selected_item, num_pairs):\n",
    "    conv_dict_1 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "    all_pairs_list_NP_DISAGREEMENT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1A'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    all_pairs_combination = list(itertools.product(all_pairs_list_PP_QA, all_pairs_list_NP_DISAGREEMENT, all_pairs_list_PP_QA))\n",
    "    selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "    for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "        conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[0]]\n",
    "        tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "        conv_dict_1['conv_' + str(index + 1)]['pair_1'] = PP_QA\n",
    "\n",
    "        NP_DISAGREEMENT = blocks_neg_100[selected_item]['Oneg1A_Opos1A'][selected_pair[1]]\n",
    "        if NP_DISAGREEMENT['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and NP_DISAGREEMENT['Opos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"] \\\n",
    "        and NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Key'])\n",
    "            tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Key'])\n",
    "            tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'])\n",
    "            tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'])\n",
    "            conv_dict_1['conv_' + str(index + 1)]['pair_2'] = NP_DISAGREEMENT\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[2]]\n",
    "        if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            REACTION = \"Ah, I see! \"\n",
    "            question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "            new_PP_QA = copy.deepcopy(PP_QA)\n",
    "            new_PP_QA['Qpos1A']['Question'] = question_text\n",
    "            conv_dict_1['conv_' + str(index + 1)]['pair_3'] = new_PP_QA\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_1['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        DECISION = \"Okay! Great! I buy this!\"\n",
    "        conv_dict_1['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "        tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "    \n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_1.keys()):\n",
    "        if conv_dict_1[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_1[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_1_test = conv_type_1(selected_item, num_pairs)\n",
    "conv_type_1_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_2(selected_item, num_pairs):\n",
    "    conv_dict_2 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "    all_pairs_list_NP_IT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1B_retrieved'].keys())\n",
    "    if all_pairs_list_NP_IT:\n",
    "\n",
    "        all_pairs_list_NP_ATR = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_list_PP_QA = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_IT, all_pairs_list_NP_ATR, all_pairs_list_PP_QA))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_2['conv_' + str(index + 1)] = {}\n",
    "                NP_IT = blocks_neg_100[selected_item]['Oneg1A_Opos1B_retrieved'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Opos1B']['Labels']['Key'])\n",
    "                aspect = NP_IT['Opos1B']['Labels']['Aspect']\n",
    "                selected_item_B = NP_IT['Opos1B']['Labels']['Key'].split(\"_\")[0]\n",
    "                conv_dict_2['conv_' + str(index + 1)]['pair_1'] = NP_IT\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Oneg1A_Opos2A_restricted'].keys()))\n",
    "                NP_ATR = blocks_neg_100[selected_item_B]['Oneg1A_Opos2A_restricted'][selected_pair_random]\n",
    "                if NP_ATR['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and NP_ATR['Opos2A']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Oneg1A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Opos2A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Oneg1A']['Labels']['Aspect'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Opos2A']['Labels']['Aspect'])\n",
    "                    \n",
    "                    REACTION = f\"Yes! {aspect} plays a key role for me! \"\n",
    "                    opinion_text = REACTION + NP_ATR['Oneg1A']['Opinion']\n",
    "                    new_NP_ATR = copy.deepcopy(NP_ATR)\n",
    "                    new_NP_ATR['Oneg1A']['Opinion'] = opinion_text\n",
    "                    conv_dict_2['conv_' + str(index + 1)]['pair_2'] = new_NP_ATR\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_2['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    REACTION = \"Ah, Ok! \"\n",
    "                    question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "                    new_PP_QA = copy.deepcopy(PP_QA)\n",
    "                    new_PP_QA['Qpos1A']['Question'] = question_text\n",
    "                    conv_dict_2['conv_' + str(index + 1)]['pair_3'] = new_PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_2['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Okay! Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_2['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_2['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_2.keys()):\n",
    "        if conv_dict_2[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_2[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_2_test = conv_type_2(selected_item, num_pairs)\n",
    "conv_type_2_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_3(selected_item, num_pairs):\n",
    "    conv_dict_3 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "    all_pairs_list_NP_IT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1B_also_view'].keys())\n",
    "    if all_pairs_list_NP_IT:\n",
    "\n",
    "        all_pairs_list_NP_ATR = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_list_PP_QA = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_IT, all_pairs_list_NP_ATR, all_pairs_list_PP_QA))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_3['conv_' + str(index + 1)] = {}\n",
    "                NP_IT = blocks_neg_100[selected_item]['Oneg1A_Opos1B_also_view'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Opos1B']['Labels']['Key'])\n",
    "                aspect = NP_IT['Opos1B']['Labels']['Aspect']\n",
    "                selected_item_B = NP_IT['Opos1B']['Labels']['Key'].split(\"_\")[0]\n",
    "                conv_dict_3['conv_' + str(index + 1)]['pair_1'] = NP_IT\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Oneg1A_Opos2A_restricted'].keys()))\n",
    "                NP_ATR = blocks_neg_100[selected_item_B]['Oneg1A_Opos2A_restricted'][selected_pair_random]\n",
    "                if NP_ATR['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and NP_ATR['Opos2A']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Oneg1A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Opos2A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Oneg1A']['Labels']['Aspect'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Opos2A']['Labels']['Aspect'])\n",
    "                    \n",
    "                    REACTION = f\"Yes! {aspect} plays a key role for me! \"\n",
    "                    opinion_text = REACTION + NP_ATR['Oneg1A']['Opinion']\n",
    "                    new_NP_ATR = copy.deepcopy(NP_ATR)\n",
    "                    new_NP_ATR['Oneg1A']['Opinion'] = opinion_text\n",
    "                    conv_dict_3['conv_' + str(index + 1)]['pair_2'] = new_NP_ATR\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_3['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    REACTION = \"Ah, Ok! \"\n",
    "                    question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "                    new_PP_QA = copy.deepcopy(PP_QA)\n",
    "                    new_PP_QA['Qpos1A']['Question'] = question_text\n",
    "                    conv_dict_3['conv_' + str(index + 1)]['pair_3'] = new_PP_QA                    \n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_3['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Okay! Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_3['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_3['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_3.keys()):\n",
    "        if conv_dict_3[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_3[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_3_test = conv_type_3(selected_item, num_pairs)\n",
    "conv_type_3_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_4(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_4 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_NP_DISAGREEMENT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1A'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_NP_DISAGREEMENT and all_pairs_list_PP_QA:\n",
    "        all_pairs_list_PP_AT = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_DISAGREEMENT, all_pairs_list_PP_QA, all_pairs_list_PP_AT))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_4['conv_' + str(index + 1)] = {}\n",
    "                NP_DISAGREEMENT = blocks_neg_100[selected_item]['Oneg1A_Opos1A'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'])\n",
    "                conv_dict_4['conv_' + str(index + 1)]['pair_1'] = NP_DISAGREEMENT\n",
    "\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "                    \n",
    "                    REACTION = \"All right! \"\n",
    "                    question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "                    new_PP_QA = copy.deepcopy(PP_QA)\n",
    "                    new_PP_QA['Qpos1A']['Question'] = question_text   \n",
    "                    conv_dict_4['conv_' + str(index + 1)]['pair_2'] = new_PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_4['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'].keys()))\n",
    "                PP_AT = blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'][selected_pair_random]\n",
    "                if PP_AT['Opos1B']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_AT['Oneg2B']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    conv_dict_4['conv_' + str(index + 1)]['pair_3'] = PP_AT\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_4['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Ah! Ok! I buy that one!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_4['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_4['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_4.keys()):\n",
    "        if conv_dict_4[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_4[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_4_test = conv_type_4(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_4_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_5(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_5 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "    all_pairs_list_NP_DISAGREEMENT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_PP_QA and all_pairs_list_NP_DISAGREEMENT:\n",
    "\n",
    "        all_pairs_list_PN_AT = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_PP_QA, all_pairs_list_PN_AT, all_pairs_list_NP_DISAGREEMENT))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_5['conv_' + str(index + 1)] = {}\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "                conv_dict_5['conv_' + str(index + 1)]['pair_1'] = PP_QA\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'].keys()))\n",
    "                PN_AT = blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'][selected_pair_random]\n",
    "                if PN_AT['Opos1B']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PN_AT['Oneg2B']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    conv_dict_5['conv_' + str(index + 1)]['pair_2'] = PN_AT\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_5['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                NP_DISAGREEMENT = blocks_neg_100[selected_item]['Oneg1A_Opos1A'][selected_pair[2]]\n",
    "                if NP_DISAGREEMENT['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and NP_DISAGREEMENT['Opos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and NP_DISAGREEMENT['Oneg1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"] \\\n",
    "                and NP_DISAGREEMENT['Opos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    REACTION = \"Ah, Ok! \"\n",
    "                    opinion_text = REACTION + NP_DISAGREEMENT['Oneg1A']['Opinion']\n",
    "                    new_NP_DISAGREEMENT = copy.deepcopy(NP_DISAGREEMENT)\n",
    "                    new_NP_DISAGREEMENT['Oneg1A']['Opinion'] = opinion_text\n",
    "                    conv_dict_5['conv_' + str(index + 1)]['pair_3'] = new_NP_DISAGREEMENT                    \n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_5['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Ok!, Great! So, I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_5['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_5['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_5.keys()):\n",
    "        if conv_dict_5[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_5[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_5_test = conv_type_5(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_5_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_6(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_6 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_NP_ATR = list(blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_NP_ATR and all_pairs_list_PP_QA:\n",
    "        all_pairs_list_PP_AGREEMENT_M = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_ATR, all_pairs_list_PP_QA, all_pairs_list_PP_AGREEMENT_M))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_6['conv_' + str(index + 1)] = {}\n",
    "                NP_ATR = blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_ATR['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_ATR['Opos2A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_ATR['Oneg1A']['Labels']['Aspect'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_ATR['Opos2A']['Labels']['Aspect'])\n",
    "                conv_dict_6['conv_' + str(index + 1)]['pair_1'] = NP_ATR\n",
    "\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_6['conv_' + str(index + 1)]['pair_2'] = PP_QA\n",
    "                    #Because we change the product\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_6['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_B]['Opos1B_Opos1B2_agreement_and_more'].keys()))\n",
    "                PP_AGREEMENT_M = blocks_pos_100[selected_item_B]['Opos1B_Opos1B2_agreement_and_more'][selected_pair_random]\n",
    "                tracking_dict[\"Key\"].append(PP_AGREEMENT_M['Opos1B']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(PP_AGREEMENT_M['Opos1B2']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_AGREEMENT_M['Opos1B']['Labels']['Aspect'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_AGREEMENT_M['Opos1B2']['Labels']['Aspect'])\n",
    "                conv_dict_6['conv_' + str(index + 1)]['pair_3'] = PP_AGREEMENT_M\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_6['conv_' + str(index + 1)]['pair_4'] = PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_6['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Ok!, Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_6['conv_' + str(index + 1)]['pair_5'] = DECISION\n",
    "            except:\n",
    "                conv_dict_6['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_6.keys()):\n",
    "        if conv_dict_6[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_6[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_6_test = conv_type_6(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_6_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_7(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_7 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_NP_ATR = list(blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_NP_ATR and all_pairs_list_PP_QA:\n",
    "        all_pairs_list_PP_AT = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_ATR, all_pairs_list_PP_QA, all_pairs_list_PP_AT))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_7['conv_' + str(index + 1)] = {}\n",
    "                NP_ATR = blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_ATR['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_ATR['Opos2A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_ATR['Oneg1A']['Labels']['Aspect'])\n",
    "                tracking_dict[\"Aspect\"].append(NP_ATR['Opos2A']['Labels']['Aspect'])\n",
    "                conv_dict_7['conv_' + str(index + 1)]['pair_1'] = NP_ATR\n",
    "\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_7['conv_' + str(index + 1)]['pair_2'] = PP_QA\n",
    "                    #Because we change the product\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_7['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_B]['Opos1B_Opos2B'].keys()))\n",
    "                PP_AT = blocks_pos_100[selected_item_B]['Opos1B_Opos2B'][selected_pair_random]\n",
    "                tracking_dict[\"Key\"].append(PP_AT['Opos1B']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(PP_AT['Opos2B']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_AT['Opos1B']['Labels']['Aspect'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_AT['Opos2B']['Labels']['Aspect'])\n",
    "                conv_dict_7['conv_' + str(index + 1)]['pair_3'] = PP_AT\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_7['conv_' + str(index + 1)]['pair_4'] = PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_7['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Ok!, Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_7['conv_' + str(index + 1)]['pair_5'] = DECISION\n",
    "            except:\n",
    "                conv_dict_7['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_7.keys()):\n",
    "        if conv_dict_7[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_7[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_7_test = conv_type_7(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_7_test['conv_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_8(selected_item, num_pairs):\n",
    "    conv_dict_8 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_QA_1 = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "    all_pairs_list_NP_IT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1B_retrieved'].keys())\n",
    "\n",
    "    if all_pairs_list_PP_QA_1 and all_pairs_list_NP_IT:\n",
    "        all_pairs_list_PP_QA_2 = list(range(1,num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_PP_QA_1, all_pairs_list_NP_IT, all_pairs_list_PP_QA_2))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_8['conv_' + str(index + 1)] = {}\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "                conv_dict_8['conv_' + str(index + 1)]['pair_1'] = PP_QA\n",
    "\n",
    "                NP_IT = blocks_neg_100[selected_item]['Oneg1A_Opos1B_retrieved'][selected_pair[1]]\n",
    "                if NP_IT['Oneg1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and NP_IT['Opos1B']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    aspect = NP_IT['Opos1B']['Labels']['Aspect']\n",
    "                    selected_item_B = NP_IT['Opos1B']['Labels']['Key'].split(\"_\")[0]\n",
    "                    REACTION = \"But \"\n",
    "                    opinion_text = REACTION + NP_IT['Oneg1A']['Opinion']\n",
    "                    new_NP_IT = copy.deepcopy(NP_IT)\n",
    "                    new_NP_IT['Oneg1A']['Opinion'] = opinion_text\n",
    "                    conv_dict_8['conv_' + str(index + 1)]['pair_2'] = new_NP_IT                    \n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_8['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                conv_dict_8['conv_' + str(index + 1)]['pair_3'] = PP_QA\n",
    "\n",
    "                DECISION = \"Okay! Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_8['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_8['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_8.keys()):\n",
    "        if conv_dict_8[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_8[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_8_test = conv_type_8(selected_item, num_pairs)\n",
    "conv_type_8_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_9(selected_item, num_pairs):\n",
    "    conv_dict_9 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_AGREEMENT_M = list(blocks_pos_100[selected_item]['Opos1B_Opos1B2_agreement_and_more'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    all_pairs_combination = list(itertools.product(all_pairs_list_PP_AGREEMENT_M, all_pairs_list_PP_QA))\n",
    "    selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "    for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "        conv_dict_9['conv_' + str(index + 1)] = {}\n",
    "        PP_AGREEMENT_M = blocks_pos_100[selected_item]['Opos1B_Opos1B2_agreement_and_more'][selected_pair[0]]\n",
    "        tracking_dict[\"Key\"].append(PP_AGREEMENT_M['Opos1B']['Labels']['Key'])\n",
    "        tracking_dict[\"Key\"].append(PP_AGREEMENT_M['Opos1B2']['Labels']['Key'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_AGREEMENT_M['Opos1B']['Labels']['Aspect'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_AGREEMENT_M['Opos1B2']['Labels']['Aspect'])\n",
    "        conv_dict_9['conv_' + str(index + 1)]['pair_1'] = PP_AGREEMENT_M\n",
    "\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "        if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            REACTION = \"Ok! Great! \"\n",
    "            question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "            new_PP_QA = copy.deepcopy(PP_QA)\n",
    "            new_PP_QA['Qpos1A']['Question'] = question_text   \n",
    "            conv_dict_9['conv_' + str(index + 1)]['pair_2'] = new_PP_QA\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_9['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        DECISION = \"Okay! I buy this!\"\n",
    "        tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "        conv_dict_9['conv_' + str(index + 1)]['pair_3'] = DECISION\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_9.keys()):\n",
    "        if conv_dict_9[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_9[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_9_test = conv_type_9(selected_item, num_pairs)\n",
    "conv_type_9_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_10(selected_item, num_pairs):\n",
    "    conv_dict_10 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_AT = list(blocks_pos_100[selected_item]['Opos1B_Opos2B'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    all_pairs_combination = list(itertools.product(all_pairs_list_PP_AT, all_pairs_list_PP_QA))\n",
    "    selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "    for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "        conv_dict_10['conv_' + str(index + 1)] = {}\n",
    "        PP_AT = blocks_pos_100[selected_item]['Opos1B_Opos2B'][selected_pair[0]]\n",
    "        tracking_dict[\"Key\"].append(PP_AT['Opos1B']['Labels']['Key'])\n",
    "        tracking_dict[\"Key\"].append(PP_AT['Opos2B']['Labels']['Key'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_AT['Opos1B']['Labels']['Aspect'])\n",
    "        tracking_dict[\"Aspect\"].append(PP_AT['Opos2B']['Labels']['Aspect'])\n",
    "        conv_dict_10['conv_' + str(index + 1)]['pair_1'] = PP_AT\n",
    "\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "        if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            REACTION = \"Ok! Great! \"\n",
    "            question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "            new_PP_QA = copy.deepcopy(PP_QA)\n",
    "            new_PP_QA['Qpos1A']['Question'] = question_text   \n",
    "            conv_dict_10['conv_' + str(index + 1)]['pair_2'] = new_PP_QA\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_10['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        DECISION = \"Okay! I buy this!\"\n",
    "        tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "        conv_dict_10['conv_' + str(index + 1)]['pair_3'] = DECISION\n",
    "    \n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_10.keys()):\n",
    "        if conv_dict_10[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_10[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_10_test = conv_type_10(selected_item, num_pairs)\n",
    "conv_type_10_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_11(selected_item, num_pairs):\n",
    "    conv_dict_11 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PN_AT = list(blocks_pos_100[selected_item]['Opos1B_Oneg2B'].keys())\n",
    "    all_pairs_list_PP_QA = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    all_pairs_combination = list(itertools.product(all_pairs_list_PN_AT, all_pairs_list_PP_QA))\n",
    "    selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "    for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "        conv_dict_11['conv_' + str(index + 1)] = {}\n",
    "        PN_AT = blocks_pos_100[selected_item]['Opos1B_Oneg2B'][selected_pair[0]]\n",
    "        tracking_dict[\"Key\"].append(PN_AT['Opos1B']['Labels']['Key'])\n",
    "        tracking_dict[\"Key\"].append(PN_AT['Oneg2B']['Labels']['Key'])\n",
    "        tracking_dict[\"Aspect\"].append(PN_AT['Opos1B']['Labels']['Aspect'])\n",
    "        tracking_dict[\"Aspect\"].append(PN_AT['Oneg2B']['Labels']['Aspect'])\n",
    "        aspect = PN_AT['Oneg2B']['Labels']['Aspect']\n",
    "        conv_dict_11['conv_' + str(index + 1)]['pair_1'] = PN_AT\n",
    "\n",
    "        PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[1]]\n",
    "        if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "        and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "            REACTION = f\"But {aspect} doesn't play a key role for me! \"\n",
    "            question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "            new_PP_QA = copy.deepcopy(PP_QA)\n",
    "            new_PP_QA['Qpos1A']['Question'] = question_text   \n",
    "            conv_dict_11['conv_' + str(index + 1)]['pair_2'] = new_PP_QA\n",
    "        else:\n",
    "            tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "            conv_dict_11['conv_' + str(index + 1)] = {}\n",
    "            continue\n",
    "\n",
    "        DECISION = \"Okay! I buy this!\"\n",
    "        tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "        conv_dict_11['conv_' + str(index + 1)]['pair_3'] = DECISION\n",
    "    \n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_11.keys()):\n",
    "        if conv_dict_11[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_11[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_11_test = conv_type_11(selected_item, num_pairs)\n",
    "conv_type_11_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_12(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_12 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PN_AT = list(blocks_pos_100[selected_item]['Opos1B_Oneg2B'].keys())\n",
    "\n",
    "    if all_pairs_list_PN_AT:\n",
    "        all_pairs_list_PP_QA = list(range(1, num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_PN_AT, all_pairs_list_PP_QA))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_12['conv_' + str(index + 1)] = {}\n",
    "                PN_AT = blocks_pos_100[selected_item]['Opos1B_Oneg2B'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(PN_AT['Opos1B']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(PN_AT['Oneg2B']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PN_AT['Oneg2B']['Labels']['Aspect'])\n",
    "                aspect = PN_AT['Oneg2B']['Labels']['Aspect']\n",
    "                conv_dict_12['conv_' + str(index + 1)]['pair_1'] = PN_AT\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "                \n",
    "                REACTION = {\"Reaction_user\": f\"Ah! {aspect} plays a key role for me!\",\n",
    "                            \"Reaction_agent\": f\"Okay! So, I can offer you this one: {selected_item_B}\"}\n",
    "                conv_dict_12['conv_' + str(index + 1)]['pair_2'] = REACTION\n",
    "\n",
    "                #REACTION = {\"Reaction_user\": f\"Ah! {aspect} plays a key role for me!\",\n",
    "                            #\"Reaction_agent\": f\"Okay! So, I can offer you this one: {selected_item_B}\"}\n",
    "                #conv_dict_12['conv_' + str(index + 1)]['pair_2'] = REACTION\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_12['conv_' + str(index + 1)]['pair_3'] = PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_12['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Ok!, I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_12['conv_' + str(index + 1)]['pair_4'] = DECISION\n",
    "            except:\n",
    "                conv_dict_12['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_12.keys()):\n",
    "        if conv_dict_12[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_12[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00AB7FVCY'\n",
    "num_pairs = 20\n",
    "conv_type_12_test = conv_type_12(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_12_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_13(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_13 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_PP_QA_1 = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "    all_pairs_list_NP_ATR = list(blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'].keys())\n",
    "    all_pairs_list_PP_QA_2 = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_PP_QA_1 and all_pairs_list_NP_ATR:\n",
    "        all_pairs_list_PN_AT = list(range(1, num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_PP_QA_1, all_pairs_list_NP_ATR, all_pairs_list_PN_AT, all_pairs_list_PP_QA_2))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_13['conv_' + str(index + 1)] = {}\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Aspect\"].append(PP_QA['Qpos1A']['Labels']['Aspect'])\n",
    "                conv_dict_13['conv_' + str(index + 1)]['pair_1'] = PP_QA\n",
    "\n",
    "                NP_ATR = blocks_neg_100[selected_item]['Oneg1A_Opos2A_restricted'][selected_pair[1]]\n",
    "                if NP_ATR['Opos2A']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Oneg1A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Key\"].append(NP_ATR['Opos2A']['Labels']['Key'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Oneg1A']['Labels']['Aspect'])\n",
    "                    tracking_dict[\"Aspect\"].append(NP_ATR['Opos2A']['Labels']['Aspect'])\n",
    "                    conv_dict_13['conv_' + str(index + 1)]['pair_2'] = NP_ATR\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_13['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_B = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'].keys()))\n",
    "                PN_AT = blocks_pos_100[selected_item_B]['Opos1B_Oneg2B'][selected_pair_random]\n",
    "                if PN_AT['Opos1B']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PN_AT['Oneg2B']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    conv_dict_13['conv_' + str(index + 1)]['pair_3'] = PN_AT\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_13['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                PP_QA = blocks_neg_100[selected_item]['Qpos1A_Apos1A'][selected_pair[3]]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    REACTION = \"Ah! Ok! \"\n",
    "                    question_text = REACTION + PP_QA['Qpos1A']['Question']\n",
    "                    new_PP_QA = copy.deepcopy(PP_QA)\n",
    "                    new_PP_QA['Qpos1A']['Question'] = question_text   \n",
    "                    conv_dict_13['conv_' + str(index + 1)]['pair_4'] = new_PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_13['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Okay! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_13['conv_' + str(index + 1)]['pair_6'] = DECISION\n",
    "            except:\n",
    "                conv_dict_13['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_13.keys()):\n",
    "        if conv_dict_13[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_13[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00FI8C9XK'\n",
    "num_pairs = 20\n",
    "conv_type_13_test = conv_type_13(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_13_test['conv_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation Type #14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_type_14(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict):\n",
    "    conv_dict_14 = {}\n",
    "    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "\n",
    "    all_pairs_list_NP_IT = list(blocks_neg_100[selected_item]['Oneg1A_Opos1B_also_view'].keys())\n",
    "    all_pairs_list_PP_QA_1 = list(blocks_neg_100[selected_item]['Qpos1A_Apos1A'].keys())\n",
    "\n",
    "    if all_pairs_list_NP_IT and all_pairs_list_PP_QA_1:\n",
    "        all_pairs_list_PP_AT = list(range(1, num_pairs))\n",
    "        all_pairs_list_PP_QA_2 = list(range(1, num_pairs))\n",
    "\n",
    "        all_pairs_combination = list(itertools.product(all_pairs_list_NP_IT, all_pairs_list_PP_QA_1, all_pairs_list_PP_AT, all_pairs_list_PP_QA_2))\n",
    "        selected_pairs_combination = select_pairs_combination(all_pairs_combination, num_pairs)\n",
    "\n",
    "        for index, selected_pair in enumerate(selected_pairs_combination):\n",
    "            try:\n",
    "                conv_dict_14['conv_' + str(index + 1)] = {}\n",
    "                NP_IT = blocks_neg_100[selected_item]['Oneg1A_Opos1B_also_view'][selected_pair[0]]\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Oneg1A']['Labels']['Key'])\n",
    "                tracking_dict[\"Key\"].append(NP_IT['Opos1B']['Labels']['Key'])\n",
    "                aspect = NP_IT['Opos1B']['Labels']['Aspect']\n",
    "                selected_item_B = NP_IT['Opos1B']['Labels']['Key'].split(\"_\")[0]\n",
    "                conv_dict_14['conv_' + str(index + 1)]['pair_1'] = NP_IT\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_B]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    tracking_dict[\"Key\"].append(PP_QA['Qpos1A']['Labels']['Key'])\n",
    "                    conv_dict_14['conv_' + str(index + 1)]['pair_2'] = PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_14['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                all_also_view_items = metaData_for_cellPhones[metaData_for_cellPhones.asin == selected_item_B].also_view.values[0]\n",
    "                all_retrieved_index, all_retrieved_items = find_retrieved_items_and_index(retrieved_items_dict, selected_item_B)\n",
    "                all_items_list = list(all_also_view_items) + all_retrieved_items\n",
    "                all_items_list = list(set(all_items_with_review).intersection(all_items_list))\n",
    "\n",
    "                selected_item_C = random.choice(all_items_list)\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_pos_100[selected_item_C]['Opos1B_Opos2B'].keys()))\n",
    "                PP_AT = blocks_pos_100[selected_item_C]['Opos1B_Opos2B'][selected_pair_random]\n",
    "                if PP_AT['Opos1B']['Labels']['Key'] not in tracking_dict[\"Key\"] and PP_AT['Opos2B']['Labels']['Key'] not in tracking_dict[\"Key\"]:\n",
    "                    tracking_dict[\"Key\"].append(PP_AT['Opos1B']['Labels']['Key'])\n",
    "                    tracking_dict[\"Key\"].append(PP_AT['Opos2B']['Labels']['Key'])\n",
    "                    tracking_dict[\"Aspect\"].append(PP_AT['Opos1B']['Labels']['Aspect'])\n",
    "                    tracking_dict[\"Aspect\"].append(PP_AT['Opos2B']['Labels']['Key'])\n",
    "                    conv_dict_14['conv_' + str(index + 1)]['pair_3'] = PP_AT\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_14['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                selected_pair_random = random.choice(list(blocks_neg_100[selected_item_C]['Qpos1A_Apos1A'].keys()))\n",
    "                PP_QA = blocks_neg_100[selected_item_C]['Qpos1A_Apos1A'][selected_pair_random]\n",
    "                if PP_QA['Qpos1A']['Labels']['Key'] not in tracking_dict[\"Key\"] \\\n",
    "                and PP_QA['Qpos1A']['Labels']['Aspect'] not in tracking_dict[\"Aspect\"]:\n",
    "                    conv_dict_14['conv_' + str(index + 1)]['pair_4'] = PP_QA\n",
    "                else:\n",
    "                    tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                    conv_dict_14['conv_' + str(index + 1)] = {}\n",
    "                    continue\n",
    "\n",
    "                DECISION = \"Okay! Great! I buy this!\"\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                conv_dict_14['conv_' + str(index + 1)]['pair_5'] = DECISION\n",
    "            except:\n",
    "                conv_dict_14['conv_' + str(index + 1)] = {}\n",
    "                tracking_dict = {\"Key\": [], \"Aspect\": []}\n",
    "                continue\n",
    "    counter = 0\n",
    "    conv_dict = {}\n",
    "    for key in list(conv_dict_14.keys()):\n",
    "        if conv_dict_14[str(key)]:\n",
    "            counter += 1\n",
    "            conv_dict['conv_' + str(counter)] = conv_dict_14[str(key)]\n",
    "    return(conv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_item = 'B00FI8C9XK'\n",
    "num_pairs = 20\n",
    "conv_type_14_test = conv_type_14(selected_item, num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "conv_type_14_test['conv_9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "num_pairs = 50\n",
    "for item_counter, item in enumerate(all_items_with_review):\n",
    "    print(item_counter + 1)\n",
    "    dataset[str(item)] = {}\n",
    "    conv_type_1_dict = conv_type_1(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_1'] = conv_type_1_dict\n",
    "    conv_type_2_dict = conv_type_2(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_2'] = conv_type_2_dict\n",
    "    conv_type_3_dict = conv_type_3(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_3'] = conv_type_3_dict\n",
    "    conv_type_4_dict = conv_type_4(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_4'] = conv_type_4_dict\n",
    "    conv_type_5_dict = conv_type_5(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_5'] = conv_type_5_dict\n",
    "    conv_type_6_dict = conv_type_6(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_6'] = conv_type_6_dict\n",
    "    conv_type_7_dict = conv_type_7(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_7'] = conv_type_7_dict\n",
    "    conv_type_8_dict = conv_type_8(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_8'] = conv_type_8_dict\n",
    "    conv_type_9_dict = conv_type_9(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_9'] = conv_type_9_dict\n",
    "    conv_type_10_dict = conv_type_10(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_10'] = conv_type_10_dict\n",
    "    conv_type_11_dict = conv_type_11(str(item), num_pairs)\n",
    "    dataset[str(item)]['conv_type_11'] = conv_type_11_dict\n",
    "    conv_type_12_dict = conv_type_12(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_12'] = conv_type_12_dict\n",
    "    conv_type_13_dict = conv_type_13(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_13'] = conv_type_13_dict\n",
    "    conv_type_14_dict = conv_type_14(str(item), num_pairs, metaData_for_cellPhones, all_items_with_review, retrieved_items_dict)\n",
    "    dataset[str(item)]['conv_type_14'] = conv_type_14_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.json', 'w') as f:\n",
    "    json.dump(dataset, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
